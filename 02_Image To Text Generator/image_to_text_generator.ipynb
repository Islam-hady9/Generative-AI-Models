{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","gpuClass":"standard"},"cells":[{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"FTN6Dks8B7_G","executionInfo":{"status":"ok","timestamp":1724431162754,"user_tz":-180,"elapsed":4146,"user":{"displayName":"Islam Abd_Elhady","userId":"06130060896100432573"}},"outputId":"16eb1022-f34a-452f-e7fd-f34c3967d7f5"},"execution_count":22,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}]},{"cell_type":"code","execution_count":23,"metadata":{"id":"SeT-a9Byby1n","executionInfo":{"status":"ok","timestamp":1724431162754,"user_tz":-180,"elapsed":3,"user":{"displayName":"Islam Abd_Elhady","userId":"06130060896100432573"}}},"outputs":[],"source":["from transformers import VisionEncoderDecoderModel, ViTImageProcessor, AutoTokenizer\n","import torch\n","from PIL import Image"]},{"cell_type":"code","source":["model = VisionEncoderDecoderModel.from_pretrained(\"nlpconnect/vit-gpt2-image-captioning\")\n","feature_extractor = ViTImageProcessor.from_pretrained(\"nlpconnect/vit-gpt2-image-captioning\")\n","tokenizer = AutoTokenizer.from_pretrained(\"nlpconnect/vit-gpt2-image-captioning\")\n","\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","model.to(device)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Gh2jscQnot8g","outputId":"b502d93c-7249-44a3-f119-ea0dd351d7bf","executionInfo":{"status":"ok","timestamp":1724431180063,"user_tz":-180,"elapsed":17311,"user":{"displayName":"Islam Abd_Elhady","userId":"06130060896100432573"}}},"execution_count":24,"outputs":[{"output_type":"execute_result","data":{"text/plain":["VisionEncoderDecoderModel(\n","  (encoder): ViTModel(\n","    (embeddings): ViTEmbeddings(\n","      (patch_embeddings): ViTPatchEmbeddings(\n","        (projection): Conv2d(3, 768, kernel_size=(16, 16), stride=(16, 16))\n","      )\n","      (dropout): Dropout(p=0.0, inplace=False)\n","    )\n","    (encoder): ViTEncoder(\n","      (layer): ModuleList(\n","        (0-11): 12 x ViTLayer(\n","          (attention): ViTAttention(\n","            (attention): ViTSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.0, inplace=False)\n","            )\n","            (output): ViTSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.0, inplace=False)\n","            )\n","          )\n","          (intermediate): ViTIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): ViTOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (dropout): Dropout(p=0.0, inplace=False)\n","          )\n","          (layernorm_before): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","          (layernorm_after): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","        )\n","      )\n","    )\n","    (layernorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","    (pooler): ViTPooler(\n","      (dense): Linear(in_features=768, out_features=768, bias=True)\n","      (activation): Tanh()\n","    )\n","  )\n","  (decoder): GPT2LMHeadModel(\n","    (transformer): GPT2Model(\n","      (wte): Embedding(50257, 768)\n","      (wpe): Embedding(1024, 768)\n","      (drop): Dropout(p=0.1, inplace=False)\n","      (h): ModuleList(\n","        (0-11): 12 x GPT2Block(\n","          (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","          (attn): GPT2Attention(\n","            (c_attn): Conv1D()\n","            (c_proj): Conv1D()\n","            (attn_dropout): Dropout(p=0.1, inplace=False)\n","            (resid_dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","          (crossattention): GPT2Attention(\n","            (c_attn): Conv1D()\n","            (q_attn): Conv1D()\n","            (c_proj): Conv1D()\n","            (attn_dropout): Dropout(p=0.1, inplace=False)\n","            (resid_dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (ln_cross_attn): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","          (mlp): GPT2MLP(\n","            (c_fc): Conv1D()\n","            (c_proj): Conv1D()\n","            (act): NewGELUActivation()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","      (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","    )\n","    (lm_head): Linear(in_features=768, out_features=50257, bias=False)\n","  )\n",")"]},"metadata":{},"execution_count":24}]},{"cell_type":"code","source":["max_length = 16\n","num_beams = 4\n","gen_kwargs = {\"max_length\": max_length, \"num_beams\": num_beams}"],"metadata":{"id":"hm6EtiPoot27","executionInfo":{"status":"ok","timestamp":1724431180064,"user_tz":-180,"elapsed":13,"user":{"displayName":"Islam Abd_Elhady","userId":"06130060896100432573"}}},"execution_count":25,"outputs":[]},{"cell_type":"code","source":["def predict_step(image_paths):\n","  images = []\n","  for image_path in image_paths:\n","    i_image = Image.open(image_path)\n","    if i_image.mode != \"RGB\":\n","      i_image = i_image.convert(mode=\"RGB\")\n","\n","    images.append(i_image)\n","\n","  pixel_values = feature_extractor(images=images, return_tensors=\"pt\").pixel_values\n","  pixel_values = pixel_values.to(device)\n","\n","  output_ids = model.generate(pixel_values, **gen_kwargs)\n","\n","  preds = tokenizer.batch_decode(output_ids, skip_special_tokens=True)\n","  preds = [pred.strip() for pred in preds]\n","  return preds"],"metadata":{"id":"FQ298E4gotu-","executionInfo":{"status":"ok","timestamp":1724431180065,"user_tz":-180,"elapsed":10,"user":{"displayName":"Islam Abd_Elhady","userId":"06130060896100432573"}}},"execution_count":26,"outputs":[]},{"cell_type":"code","source":["image_path = input(\"Enter the image path: \")\n","print(\"\\n\")\n","print(f\"Predicted Caption: {predict_step([image_path])}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jEC6rrjKD3By","executionInfo":{"status":"ok","timestamp":1724431232976,"user_tz":-180,"elapsed":4804,"user":{"displayName":"Islam Abd_Elhady","userId":"06130060896100432573"}},"outputId":"89fe22d4-a3d8-46d6-f76e-6c07392f429c"},"execution_count":29,"outputs":[{"output_type":"stream","name":"stdout","text":["Enter the image path: /content/drive/MyDrive/Generative AI Models/02_Image To Text Generator/demo_images/03_sunset_picture.jpg\n","\n","\n","Predicted Caption: ['a sunset view of a sunset with the sun shining through']\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"LGUB1yF-EkGT","executionInfo":{"status":"ok","timestamp":1724431209703,"user_tz":-180,"elapsed":11,"user":{"displayName":"Islam Abd_Elhady","userId":"06130060896100432573"}}},"execution_count":27,"outputs":[]}]}